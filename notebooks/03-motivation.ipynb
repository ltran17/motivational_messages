{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9cb2cbfc-85f7-4933-8b9a-cae307fa2333",
   "metadata": {},
   "source": [
    "# Extract motivational messages\n",
    "\n",
    "I conceived of this project the same week as ChatGPT3 exploded into conversations at work, online, and at home. While my original plan had been to practice my NLP skills, I switched my goal to learn how to use this new tool.\n",
    "\n",
    "1. Load transcripts from the output of the [previous notebook](https://github.com/ltran17/motivational_messages/blob/main/notebooks/02-transcripts.ipynb).\n",
    "2. Interpret response from ChatGPT3\n",
    "3. Play with the parameters of request\n",
    "4. Summarize motivational talks for each video\n",
    "5. Save the motivational messages\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d9327d1-11dc-4fb5-bd0e-94ed57b3ba3e",
   "metadata": {},
   "source": [
    "### 1. Load transcripts from the output of the previous notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b53bf816-971c-47a9-9e69-42109aa9e084",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2b0e0e5-e633-4298-881f-791cc6ccdd45",
   "metadata": {},
   "source": [
    "* I do not push data to code repositories, and encourage you to do the same. To keep everything organized on my machine, I have a `data` folder in my project and include this folder in the project's `.gitignore` file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b0e05bae-dcd3-42e9-bbfc-bc66293b1313",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = '../data/2023-01-effort-motivations.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2b6ab805-06d1-46cd-a970-ee744b438398",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>vid</th>\n",
       "      <th>motivation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2023-01-02</td>\n",
       "      <td>qLKflJjWDi4</td>\n",
       "      <td>big exhale shift your hips up and forward and...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2023-01-03</td>\n",
       "      <td>NzIylrLhkJ4</td>\n",
       "      <td>amazing job rest back on your glutes you did ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2023-01-04</td>\n",
       "      <td>A5kHPgAi3I0</td>\n",
       "      <td>break deep breath nice wide stance hinge forw...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2023-01-06</td>\n",
       "      <td>A67VMX9hlmc</td>\n",
       "      <td>give me two minutes here nice wide stance exh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2023-01-07</td>\n",
       "      <td>lpv4RdNefyU</td>\n",
       "      <td>amazing work give me two minutes do not leave...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        date          vid                                         motivation\n",
       "0 2023-01-02  qLKflJjWDi4   big exhale shift your hips up and forward and...\n",
       "1 2023-01-03  NzIylrLhkJ4   amazing job rest back on your glutes you did ...\n",
       "2 2023-01-04  A5kHPgAi3I0   break deep breath nice wide stance hinge forw...\n",
       "3 2023-01-06  A67VMX9hlmc   give me two minutes here nice wide stance exh...\n",
       "4 2023-01-07  lpv4RdNefyU   amazing work give me two minutes do not leave..."
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(filename, parse_dates=['date'])\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a291d59b-5539-4111-a323-5da5ccf21ea3",
   "metadata": {},
   "source": [
    "### 2. Interpret response from ChatGPT3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2f9a3dc-9cc0-4ca7-90b2-cdca9b199b91",
   "metadata": {},
   "source": [
    "* ChatGPT3 has multiple language models available for use. It looks like [Davinci](https://platform.openai.com/docs/models/davinci) will be the right one for this task of interpreting and summarizing.\n",
    "\n",
    "* Different models will give different results. The creators of an endless, AI-generated, Seinfeld parody [learned this the hard way](https://wapo.st/3I7BSHW) when they switched from Davinci to Curie.\n",
    "\n",
    "* For this project, I am not worried about generating hateful or harming content. I am taking note of [OpenAI's moderation tools](https://platform.openai.com/docs/guides/moderation/overview) for future work.\n",
    "\n",
    "* The next three cells are set up."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "19e19897-6e74-4a8a-84f1-71287aa51fe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../config/chat_gpt3_api') as file:\n",
    "    CHAT_KEY = file.readline()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e222c7b-fcb2-446c-b4c9-e8047186a4ea",
   "metadata": {},
   "source": [
    "* Even more important than not pushing data to a code repository is to **never push a key to a code repository**! I have stored the keys in a folder called `config` and added this folder to the project's `.gitignore` file. There are other ways to accomplish this, choose your preferred method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "34fa6b4b-8354-48d8-bd30-a4453aad264e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "openai.api_key = CHAT_KEY\n",
    "models = openai.Model.list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "24ae7768-3bb0-4cbe-b677-b3a7c9126dff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' big exhale shift your hips up and forward and before you head out if this is your first workout or '"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_text = data.loc[0,'motivation']\n",
    "test_text[:100]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1099cd5-abe5-48a6-a5ce-f3aa3010e069",
   "metadata": {},
   "source": [
    "* The template for the function in the next cell comes from OpenAI. If you used the playground when you were setting up API access, you already encountered the `temperature` and `max_tokens` parameters.\n",
    "\n",
    "* I interpret `temperature` as a creativity setting. Set to 0, multiple calls with the same text will return similar (if not identical) responses. Set to 1, the model gets very creative! \n",
    "\n",
    "* You can find no better explanation of OpenAI's tokens than the [documentation](https://help.openai.com/en/articles/4936856-what-are-tokens-and-how-to-count-them) from the source. If you want a more general discussion of tokens and tokenization, send \"nlp tokens\" through your favorite search engine to learn more."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9895afab-050c-4f40-962d-2ae4291fa650",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_response(text):\n",
    "    prompt = 'extract the motivational message from the following text and summarize in three sentences: '\n",
    "    response = openai.Completion.create(\n",
    "        model='text-davinci-003',\n",
    "        prompt=prompt+text,\n",
    "        temperature=0.7,\n",
    "        max_tokens=25\n",
    "    )\n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "6d326011-2ebe-4278-8f2a-b0d94a1936c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<OpenAIObject text_completion id=cmpl-6hfQV5TTlYKCopTdgWTXgb5zauFPo at 0x7fbf50bd6160> JSON: {\n",
       "  \"choices\": [\n",
       "    {\n",
       "      \"finish_reason\": \"length\",\n",
       "      \"index\": 0,\n",
       "      \"logprobs\": null,\n",
       "      \"text\": \"\\n\\nThis motivational message encourages applying effort not just when we're in the mood, but when we show up consistently. It\"\n",
       "    }\n",
       "  ],\n",
       "  \"created\": 1675865367,\n",
       "  \"id\": \"cmpl-6hfQV5TTlYKCopTdgWTXgb5zauFPo\",\n",
       "  \"model\": \"text-davinci-003\",\n",
       "  \"object\": \"text_completion\",\n",
       "  \"usage\": {\n",
       "    \"completion_tokens\": 25,\n",
       "    \"prompt_tokens\": 464,\n",
       "    \"total_tokens\": 489\n",
       "  }\n",
       "}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = get_response(test_text)\n",
    "response"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8725e36-36fa-4eea-9b4c-3285ca0d0626",
   "metadata": {},
   "source": [
    "* For a first pass, this is a pretty good summary! Let me see how to extract it from the response."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "174fd074-f689-4fc4-b7e7-61b37c0a02fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\n\\nThis motivational message encourages applying effort not just when we're in the mood, but when we show up consistently. It\""
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response['choices'][0]['text']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f106885-d587-4bac-b54e-e9c4df0d77ee",
   "metadata": {},
   "source": [
    "* I notice that it cut off the summary -- no doubt because I limited the `max_tokens` to 25.\n",
    "\n",
    "* I also notice that it really sounds like a summary! I would rather it sound like a motivational message. I need to adjust the prompt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "e30984db-a7b3-439c-a2b0-87fe2ed522d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_response(text):\n",
    "    prompt = 'extract the motivational message from the following text in three sentences: '\n",
    "    response = openai.Completion.create(\n",
    "        model='text-davinci-003',\n",
    "        prompt=prompt+text,\n",
    "        temperature=0.7,\n",
    "        max_tokens=100\n",
    "    )\n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "82fa4df3-bf64-4a4d-9587-d1f246731831",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n\\nEffort is an important part of achieving success and making progress towards your goals. Showing up and not giving up is the key to making progress and reaching your goals. Subscribe to the channel to help more people have access to high quality fitness and stay dedicated to putting in the effort every day.'"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = get_response(test_text)\n",
    "response['choices'][0]['text']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef38e1e1-9543-422c-9bb3-6ea91da08582",
   "metadata": {},
   "source": [
    "* This sounds better! However, the model is interpreting some of the boilerplate text as motivational. Adjust the prompt further."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "3902f51d-c571-47ca-a433-93d2146a429c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_response(text):\n",
    "    directions = 'extract the motivational message from the following text in three sentences: '\n",
    "    conditions = 'Ignore sentences that direct viewers to subscribe, like, buy, or comment.'\n",
    "    response = openai.Completion.create(\n",
    "        model='text-davinci-003',\n",
    "        prompt=directions+text+conditions,\n",
    "        temperature=0.7,\n",
    "        max_tokens=100\n",
    "    )\n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "f5e716e3-7d6c-42cd-81ec-155f52b50914",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\" Motivation comes from within, so remember to stay determined and dedicated to your goals. Show up and never give up, even when you don't feel motivated. Effort will show you that you can do more than you thought and help you reach your goals.\""
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = get_response(test_text)\n",
    "response['choices'][0]['text']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84aa865a-0934-43de-abf9-be84442cd67f",
   "metadata": {},
   "source": [
    "* Not bad! This sounds almost like Sydney herself. I am going to move on with the `get_response` function as defined above.\n",
    "\n",
    "* Before I get the motivations from all of the videos, I'll write a couple of functions streamline this process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "453c2783-866e-4ce6-9f1f-accc2576b8f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_text(response):\n",
    "    '''\n",
    "    Return the text from the response object\n",
    "    '''\n",
    "    text = response['choices'][0]['text']\n",
    "    return text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a239b80-d20e-4362-90eb-a755a2bfb512",
   "metadata": {},
   "source": [
    "* Also, I will be polite by pausing between requests. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "4840294c-0898-4ab2-93e3-27eaebfb5caf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "ccb4df90-47fe-402e-8b20-db4c0ceb04f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_motivation(text, sleep_time = 3):\n",
    "    '''\n",
    "    Return the extracted motivation from the text, pausing for sleep_time seconds after request.\n",
    "    '''\n",
    "    response = get_response(text)\n",
    "    motivation = extract_text(response)\n",
    "    time.sleep(sleep_time)\n",
    "    return motivation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c3e3ebb-c109-410d-8a83-231e751b08f2",
   "metadata": {},
   "source": [
    "* Test this out..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "c88d2a3f-8515-49bc-bddb-1333f9d689c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\" Motivate yourself to stay dedicated, consistent, and determined with your lifestyle or goal. Put in the effort and don't give up - even when you're not feeling motivated or in the mood. Show up and keep growing together.\""
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_motivation(test_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05e94798-8fcd-41a1-98c4-20ff03daed22",
   "metadata": {},
   "source": [
    "* Alright! I am ready to get the motivations for the month! \n",
    "\n",
    "* This next call will take a minute because of (1) the sleep parameter and (2) however busy the ChatGPT3 servers are. In fact...the first time I ran the next cell, it returned a rate limit error. That's what happens when the entire US is awake and pinging the servers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "b0997c4f-6730-45b6-b837-d5a628b37a46",
   "metadata": {},
   "outputs": [
    {
     "ename": "RateLimitError",
     "evalue": "The server had an error while processing your request. Sorry about that!",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRateLimitError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[43], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m motivations \u001b[38;5;241m=\u001b[39m \u001b[43mdata\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmotivation\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mget_motivation\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      2\u001b[0m motivations[\u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[0;32m/opt/anaconda3/envs/youtube/lib/python3.10/site-packages/pandas/core/series.py:4771\u001b[0m, in \u001b[0;36mSeries.apply\u001b[0;34m(self, func, convert_dtype, args, **kwargs)\u001b[0m\n\u001b[1;32m   4661\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply\u001b[39m(\n\u001b[1;32m   4662\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   4663\u001b[0m     func: AggFuncType,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   4666\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m   4667\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m DataFrame \u001b[38;5;241m|\u001b[39m Series:\n\u001b[1;32m   4668\u001b[0m     \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   4669\u001b[0m \u001b[38;5;124;03m    Invoke function on values of Series.\u001b[39;00m\n\u001b[1;32m   4670\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   4769\u001b[0m \u001b[38;5;124;03m    dtype: float64\u001b[39;00m\n\u001b[1;32m   4770\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 4771\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mSeriesApply\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconvert_dtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/youtube/lib/python3.10/site-packages/pandas/core/apply.py:1105\u001b[0m, in \u001b[0;36mSeriesApply.apply\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1102\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply_str()\n\u001b[1;32m   1104\u001b[0m \u001b[38;5;66;03m# self.f is Callable\u001b[39;00m\n\u001b[0;32m-> 1105\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_standard\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/youtube/lib/python3.10/site-packages/pandas/core/apply.py:1156\u001b[0m, in \u001b[0;36mSeriesApply.apply_standard\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1154\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1155\u001b[0m         values \u001b[38;5;241m=\u001b[39m obj\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mobject\u001b[39m)\u001b[38;5;241m.\u001b[39m_values\n\u001b[0;32m-> 1156\u001b[0m         mapped \u001b[38;5;241m=\u001b[39m \u001b[43mlib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap_infer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1157\u001b[0m \u001b[43m            \u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1158\u001b[0m \u001b[43m            \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1159\u001b[0m \u001b[43m            \u001b[49m\u001b[43mconvert\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconvert_dtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1160\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1162\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(mapped) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(mapped[\u001b[38;5;241m0\u001b[39m], ABCSeries):\n\u001b[1;32m   1163\u001b[0m     \u001b[38;5;66;03m# GH#43986 Need to do list(mapped) in order to get treated as nested\u001b[39;00m\n\u001b[1;32m   1164\u001b[0m     \u001b[38;5;66;03m#  See also GH#25959 regarding EA support\u001b[39;00m\n\u001b[1;32m   1165\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m obj\u001b[38;5;241m.\u001b[39m_constructor_expanddim(\u001b[38;5;28mlist\u001b[39m(mapped), index\u001b[38;5;241m=\u001b[39mobj\u001b[38;5;241m.\u001b[39mindex)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/youtube/lib/python3.10/site-packages/pandas/_libs/lib.pyx:2918\u001b[0m, in \u001b[0;36mpandas._libs.lib.map_infer\u001b[0;34m()\u001b[0m\n",
      "Cell \u001b[0;32mIn[39], line 5\u001b[0m, in \u001b[0;36mget_motivation\u001b[0;34m(text, sleep_time)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_motivation\u001b[39m(text, sleep_time \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m3\u001b[39m):\n\u001b[1;32m      2\u001b[0m     \u001b[38;5;124;03m'''\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;124;03m    Return the extracted motivation from the text, pausing for sleep_time seconds after request.\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;124;03m    '''\u001b[39;00m\n\u001b[0;32m----> 5\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43mget_response\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      6\u001b[0m     motivation \u001b[38;5;241m=\u001b[39m extract_text(response)\n\u001b[1;32m      7\u001b[0m     time\u001b[38;5;241m.\u001b[39msleep(sleep_time)\n",
      "Cell \u001b[0;32mIn[42], line 4\u001b[0m, in \u001b[0;36mget_response\u001b[0;34m(text)\u001b[0m\n\u001b[1;32m      2\u001b[0m directions \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mextract the motivational message from the following text in three sentences: \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m      3\u001b[0m conditions \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mIgnore sentences that direct viewers to subscribe, like, buy, or comment.\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m----> 4\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[43mopenai\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mCompletion\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtext-davinci-003\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43mprompt\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdirections\u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43mtext\u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43mconditions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.7\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_tokens\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m100\u001b[39;49m\n\u001b[1;32m      9\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "File \u001b[0;32m/opt/anaconda3/envs/youtube/lib/python3.10/site-packages/openai/api_resources/completion.py:25\u001b[0m, in \u001b[0;36mCompletion.create\u001b[0;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m     24\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 25\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     26\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m TryAgain \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     27\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m>\u001b[39m start \u001b[38;5;241m+\u001b[39m timeout:\n",
      "File \u001b[0;32m/opt/anaconda3/envs/youtube/lib/python3.10/site-packages/openai/api_resources/abstract/engine_api_resource.py:153\u001b[0m, in \u001b[0;36mEngineAPIResource.create\u001b[0;34m(cls, api_key, api_base, api_type, request_id, api_version, organization, **params)\u001b[0m\n\u001b[1;32m    127\u001b[0m \u001b[38;5;129m@classmethod\u001b[39m\n\u001b[1;32m    128\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcreate\u001b[39m(\n\u001b[1;32m    129\u001b[0m     \u001b[38;5;28mcls\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    136\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparams,\n\u001b[1;32m    137\u001b[0m ):\n\u001b[1;32m    138\u001b[0m     (\n\u001b[1;32m    139\u001b[0m         deployment_id,\n\u001b[1;32m    140\u001b[0m         engine,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    150\u001b[0m         api_key, api_base, api_type, api_version, organization, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparams\n\u001b[1;32m    151\u001b[0m     )\n\u001b[0;32m--> 153\u001b[0m     response, _, api_key \u001b[38;5;241m=\u001b[39m \u001b[43mrequestor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    154\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpost\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    155\u001b[0m \u001b[43m        \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    156\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparams\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    157\u001b[0m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    158\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    159\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrequest_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    160\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrequest_timeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    161\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    163\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m stream:\n\u001b[1;32m    164\u001b[0m         \u001b[38;5;66;03m# must be an iterator\u001b[39;00m\n\u001b[1;32m    165\u001b[0m         \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(response, OpenAIResponse)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/youtube/lib/python3.10/site-packages/openai/api_requestor.py:227\u001b[0m, in \u001b[0;36mAPIRequestor.request\u001b[0;34m(self, method, url, params, headers, files, stream, request_id, request_timeout)\u001b[0m\n\u001b[1;32m    206\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrequest\u001b[39m(\n\u001b[1;32m    207\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    208\u001b[0m     method,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    215\u001b[0m     request_timeout: Optional[Union[\u001b[38;5;28mfloat\u001b[39m, Tuple[\u001b[38;5;28mfloat\u001b[39m, \u001b[38;5;28mfloat\u001b[39m]]] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    216\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[Union[OpenAIResponse, Iterator[OpenAIResponse]], \u001b[38;5;28mbool\u001b[39m, \u001b[38;5;28mstr\u001b[39m]:\n\u001b[1;32m    217\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrequest_raw(\n\u001b[1;32m    218\u001b[0m         method\u001b[38;5;241m.\u001b[39mlower(),\n\u001b[1;32m    219\u001b[0m         url,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    225\u001b[0m         request_timeout\u001b[38;5;241m=\u001b[39mrequest_timeout,\n\u001b[1;32m    226\u001b[0m     )\n\u001b[0;32m--> 227\u001b[0m     resp, got_stream \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_interpret_response\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresult\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    228\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m resp, got_stream, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapi_key\n",
      "File \u001b[0;32m/opt/anaconda3/envs/youtube/lib/python3.10/site-packages/openai/api_requestor.py:620\u001b[0m, in \u001b[0;36mAPIRequestor._interpret_response\u001b[0;34m(self, result, stream)\u001b[0m\n\u001b[1;32m    612\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m (\n\u001b[1;32m    613\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_interpret_response_line(\n\u001b[1;32m    614\u001b[0m             line, result\u001b[38;5;241m.\u001b[39mstatus_code, result\u001b[38;5;241m.\u001b[39mheaders, stream\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    615\u001b[0m         )\n\u001b[1;32m    616\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m line \u001b[38;5;129;01min\u001b[39;00m parse_stream(result\u001b[38;5;241m.\u001b[39miter_lines())\n\u001b[1;32m    617\u001b[0m     ), \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    618\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    619\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m (\n\u001b[0;32m--> 620\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_interpret_response_line\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    621\u001b[0m \u001b[43m            \u001b[49m\u001b[43mresult\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcontent\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mutf-8\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    622\u001b[0m \u001b[43m            \u001b[49m\u001b[43mresult\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstatus_code\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    623\u001b[0m \u001b[43m            \u001b[49m\u001b[43mresult\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    624\u001b[0m \u001b[43m            \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    625\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m,\n\u001b[1;32m    626\u001b[0m         \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    627\u001b[0m     )\n",
      "File \u001b[0;32m/opt/anaconda3/envs/youtube/lib/python3.10/site-packages/openai/api_requestor.py:680\u001b[0m, in \u001b[0;36mAPIRequestor._interpret_response_line\u001b[0;34m(self, rbody, rcode, rheaders, stream)\u001b[0m\n\u001b[1;32m    678\u001b[0m stream_error \u001b[38;5;241m=\u001b[39m stream \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124merror\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m resp\u001b[38;5;241m.\u001b[39mdata\n\u001b[1;32m    679\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m stream_error \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;241m200\u001b[39m \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m rcode \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m300\u001b[39m:\n\u001b[0;32m--> 680\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandle_error_response(\n\u001b[1;32m    681\u001b[0m         rbody, rcode, resp\u001b[38;5;241m.\u001b[39mdata, rheaders, stream_error\u001b[38;5;241m=\u001b[39mstream_error\n\u001b[1;32m    682\u001b[0m     )\n\u001b[1;32m    683\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m resp\n",
      "\u001b[0;31mRateLimitError\u001b[0m: The server had an error while processing your request. Sorry about that!"
     ]
    }
   ],
   "source": [
    "motivations = data['motivation'].apply(get_motivation)\n",
    "motivations[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f8d0ef9-e4cd-442f-a60e-3b8435f8e009",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29bf0356-5e47-4303-842c-2b6334e2eea6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
